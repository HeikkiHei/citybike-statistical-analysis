{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citybike statistical analysis with multiple linear regession (test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read and combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_data = \"hourly-avg-2017-06-all-stations.csv\"\n",
    "\n",
    "rain_data = \"fmi-raindata-Helsinki-Kaisaniemi-2017-06.csv\"\n",
    "\n",
    "temp_data = \"fmi-weatherdata-Helsinki-Kaisaniemi-2017.csv\"\n",
    "\n",
    "A = pd.read_csv(avail_data, sep=',')\n",
    "B = pd.read_csv(rain_data, sep=',')\n",
    "C = pd.read_csv(temp_data, sep=\",\")\n",
    "\n",
    "C.rename(columns={'Vuosi': 'Vuosi', 'Kk': 'Kk', 'Pv': 'Pv', 'Klo': 'Klo', 'Aikavyöhyke': 'Aikavyöhyke', 'Sateen intensiteetti (mm/h)': 'Sateen_intensiteetti_mm_h', 'Ilman lämpötila (degC)': 'Ilman_lampotila'}, inplace=True)  \n",
    "\n",
    "# Let's take all the Temperature values from the column 'Ilman_lampotila' so that we begin with the june (Kk==6) values and continue until we reach the length of 720, this is just for model-testing purposes \n",
    "C_ilma = C['Ilman_lampotila'].iloc[1465:2185] \n",
    "#C.drop(columns='Ilman_lampotila')\n",
    "A['Sade'] = B['Sade']\n",
    "A['Ilman_lampotila'] = C_ilma\n",
    "#A['Ilman_lampotila'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Double-check that the DataFrame 'A' has 4 columns with their specific names, e.g. 'timehour', 'sumofhourlyavg', 'Sade' and 'Ilman_lampotila'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 4)\n",
      "Index(['timehour', 'sumofhourlyavg', 'Sade', 'Ilman_lampotila'], dtype='object')\n",
      "timehour            object\n",
      "sumofhourlyavg     float64\n",
      "Sade               float64\n",
      "Ilman_lampotila    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(A.shape)\n",
    "print(A.columns)\n",
    "print(A.dtypes) # Double-check: all of our variables for the model are the type float64, so no categorical variables around, that's good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['Ilman_lampotila'] = np.float64(18) # this is done for testing purposes, the fact that nulls didn't exist in C but when assigned to A's column, they suddenly exist, should be something to figure out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timehour            object\n",
       "sumofhourlyavg     float64\n",
       "Sade               float64\n",
       "Ilman_lampotila    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A['Ilman_lampotila'].isnull().values.any() # this is done for testing purposes, the fact that nulls didn't exist in C but when assigned to A's column, they suddenly exist, should be something to figure out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Assigning 'sumofhourlyavg' as the dependent variable y\n",
    "##### Assigning 'Sade' and 'Ilman_lampotila' as independent variables X (X is 2xn matrix here but it will still need the weekday-info and hour-columns to be complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = A.loc[:, ['Sade','Ilman_lampotila']] # matrix of independent variables 'Sade' and 'Ilman_lampotila'\n",
    "y = A[A.columns[1]] # vector of 'sumofhourlyavg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting the dataset 'A' into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state = 0) # 144 (0.2) observations to test-set and 576 (0.8) observations to the train-set\n",
    "\n",
    "# Feature scaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fitting Multiple Linear Regression to the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Creating a regressor object of LinearRegression class\n",
    "regressor = LinearRegression()\n",
    "\n",
    "# Applying fit-method to the training set\n",
    "regressor.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing the performance of multiple linear regression model (predicting test set results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking how well the linear regression model fits to the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015354948259910128\n"
     ]
    }
   ],
   "source": [
    "R_2 = regressor.score(X_train, y_train)\n",
    "print(R_2)  # 0.015354948259910128  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### R-squared is the statistical measure that tells how close the data are to the fitted regression line. The value range is from 0 to 1 where 1 would mean perfect fit and 0 represents a model that does not explain any of the variation in the response variable. So in this case, especially when needed to apply hardcoding for replacing quickly the temperature variable's nulls, the model ended up only 0,015 so only 1,5%. The rule of thumb: the larger the R**2, the better the regression model fits to the observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting the prediction-vector y_pred to a csv-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_df = pd.DataFrame(y_pred)\n",
    "y_pred_df.to_csv('test_predictions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
